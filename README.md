# A-comparative-analysis-on-speeech-emotion-classification-models
This is my final year thesis project. In this project i tried to show a comparative analysis on speech emotion recognition.



Here, We worked on IEMOCAP dataset which was realized by the University of Southern California.  The dataset has three types of data: text, audio, and video.  We worked on the only text and audio dataset. 


We have divided our experiment into three parts:

1. Audio only

2. Text only

3. Combined(Audio+Text)


We have used five machine learning and two deep learning models.


Machine Learning

1. Random Forest

2. Xtreme Gradient Boosting

3. Multinomial Naive Bayes 

4. Support Vector Machine 

5. Logistic Regression 


Deep Learning

1. Multi-layer Perceptron

2. Long Short Term Memory (Audio only)



Steps:

1. First, we extract the emotion label from the datasets.

2. audio vectors 

3. extract features from audio wav files

4. pre-process audio and text features dataset. 

5. audio classification models

6. text classification models

7. combined (audio+text) classification models

